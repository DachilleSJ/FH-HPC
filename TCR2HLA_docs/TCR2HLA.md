# Using TCR2HLA

See previous md file about using Slurm to run TCR2HLA on the cluster. 

## Setup

Ensure that you have a clone of [this github repo](https://github.com/kmayerb/TCR2HLA) or have a conda/mamba environment setup with TCR2HLA and its dependencies (install using pip). See Koshlan's linked github repo for more in depth information. If you plan to make any changes to TCR2HLA to customize, use the repo version.

either

```
git clone https://github.com/kmayerb/TCR2HLA.git
```

or 

```
pip install "git+https://github.com/kmayerb/TCR2HLA.git"
```

You can run this code form a node on the HPC using ipython (type ipython to start an instance).

## Generating HLA Boolean file

To work within TCR2HLA, the HLA file will need to be in a boolean array, where sample ID is on one axis, and HLA on the other. The array will be filled with True or False values for each combination.

An example of how this was done is using ``/Volumes/fh/fast/thomas_p/grp/dachille/koshlan_code_only/000_assess_hla_data.py`` on this HLA data ``/Volumes/fh/fast/thomas_p/grp/dachille/TOT15_BulkTCRAnalysis/HLA.4digits.csv``. The HLA data is in a tabular format which is converted into this matrix here ``/Volumes/fh/fast/thomas_p/grp/dachille/TOT15_BulkTCRAnalysis/20260115_tot15_hla_boolean.tsv``.

## Parsing and Formatting Clone Data

In addition to the HLA formatting, the TCR clone data will need to be formatted as well. There are parsing functions which will parse data, but ensure that it is compatible with your data. 

Data is most compatible in .tsv or .csv format. Convert your files to this type to ensure the best compatibility.

Once you have your files of interest, compress them into a zip, as TCR2HLA will read from there. 

In my example case here (``/Volumes/fh/fast/thomas_p/grp/dachille/TOT15_BulkTCRAnalysis/filtered_noMAIT``), the data is a MixCR output, which needs specific consideration on how V genes are named, as adaptive has a different naming convention. 

Additionally, some regex filtering will need to be done on the amino acid sequences to ensure that they dont contain characters like '*', '-', or '_'.  There are some other column name considerations, see the ``tot15_project_parser()`` function in ``/Volumes/fh/fast/thomas_p/grp/dachille/koshlan_code_only/001_run_tcr2hla.py`` for more in depth considerations. Koshlan wrote a ``tot15parser`` function which lives in this file, and is used in the next section.

From there, you'll run the ``stratv_v2_parmap()`` function to generate your stratv files, which contain files formatted to run alongside your HLA matrix. You can also combine multible samples into a single .csv file for use by running ``combine_stratv``.


Overall, you'll need an input file, containing as many columns as you'd like, but only containing boolean True/False values. You will also need an index/sample_name column which contains the name of your clone filenames, but strips the file extension from the end. 

For my example, I have a matrix of all HLAs and if each sample is from a patient with allergy. It looks something like this:

| sample_name | HLA_A0201 | Allergy  |
|-------------|-----------|----------|
| Batch1.TRB  | True      | False    |
| Batch2.TRB  | False     | False    |
| Batch3.TRB  | True      | True     |

This will go hand in hand with your zipped TCR clone data file. 

## Running the code

Since there can be tens of millions of TCR sequences, it's best to run these jobs on the cluster. Ensure you have read the previous .md file on how to use the HPC at the FH if you are unclear how to use it. 

SSH into the rhino node you typically use, and create a tmux session. Use ``source ~/.bashrc`` to make your conda/mamba environments available. Activate an env that contains ipython, pandas, numpy, parmap, tqdm, scipy, and TCR2HLA (im using a local clone of the repo, but you can also install it with ``pip install tcr2hla``). Type ``ipython`` to activate a python session to begin running code. 

Feel free to use '/fh/fast/thomas_p/grp/dachille/koshlan_code_only/001k_run_tcr2hla.py' as a reference (please do not edit this file). This file has some setup at the top where the boolean file was modified.

### Runnning header

The header loads in the packages that you'll need to run your code. Copy and paste your header into your ipython session and run it. 

### Loading in data

Bring in the files. In my example here, on line 59, we will load in ``path_to_binary_file``, which is the boolean matrix file desribed earlier. We also run the VfamCDR3 function, and specify the input zip location. Additionally, we specify the threshold we'd like for the binary file, so in the example file, the value is set to .05, which keeps values that occur in 5% or more of samples. This can be modified to fit the analysis. 

``run_direct_finder`` is the function which will actually kick off the jobs. Inside it, there is a parameter 'launch', which if set to True, will kick off the sbatch jobs. 


## Next time, playing with the output data.
